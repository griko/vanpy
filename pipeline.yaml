input_dir: 'speech_examples_small'
segment_name_separator: "_"
intermediate_payload_path: 'results'
# device: 'cpu'  # 'cpu'/'cuda'
log_each_x_records: 1000

preprocessing:
  file_mapper:
    save_payload: false  # use it if you want to save the payload when the component process is completed
    load_payload: false  # use it if you want to load a previously saved payload, overrides listing of an input_path
    load_df_path: '{{intermediate_payload_path}}/preprocessing_silero_vad_df_20221031175555_final.csv'
    load_meta_path: '{{intermediate_payload_path}}/preprocessing_silero_vad_metadata_20221031175555_final.pickle'
  wav_converter:
    output_dir: 'convert_preprocessed'
    ab: '256k'  # bitrate, may not be considered depending on a chosen codec
    ac: 1       # number of channels
    ar: '16k'   # sample frequency
    acodec: 'pcm_s16le'  # specify codec
    use_dir_name_as_prefix: true  # will name converted file with parent_dir prefix:
                                  # '<path>/<parent_dir>/<filename>' -> '<ouput_dir>/<parent_dir>_<filename>'
    overwrite: false
    save_payload: true
  ina_speech_segmenter:
    output_dir: 'ina_preprocessed'
    filtered_dir: 'ina_filtered'
    add_segment_metadata: true
    performance_measurement: true
    vad_engine: 'sm'
    overwrite: false
    save_payload: true
  pyannote_vad:
    output_dir: 'pyannote_vad_preprocessed'
    add_segment_metadata: true
    performance_measurement: true
    keep_only_first_segment: true
    onset: 0.85             # onset activation threshold
    offset: 0.8             # offset activation threshold
    min_duration_on: 0.1    # remove speech regions shorter than that many seconds
    min_duration_off: 0.0   # fill non-speech regions shorter than that many seconds
    overwrite: false
    save_payload: true
  silero_vad:
    output_dir: '{{input_dir}}/silero_vad_preprocessed'
    add_segment_metadata: true
    performance_measurement: true
    keep_only_first_segment: true
    sampling_rate: 16000
    overwrite: false
    save_payload: true
    save_payload_periodicity: 50000  # save intermediate payload results every X processed files
#  espnet_se:
#    output_dir: 'espnet_se_preprocessed'
#    performance_measurement: true
#    sampling_rate: 16000

feature_extraction:
  librosa_features_extractor:
    performance_measurement: true
    sampling_rate: 16000
    n_mfcc: 13
    features:
      - mfcc
      - delta_mfcc
      - zero_crossing_rate
      - spectral_centroid
      - spectral_bandwidth
      - spectral_contrast
      - spectral_flatness
    save_payload: true
    save_payload_periodicity: 50000  # save intermediate payload results every X processed files
  pyannote_embedding:
    performance_measurement: true
    sliding_window_duration: 3.0
    sliding_window_step: 1.0
    save_payload: true
    save_payload_periodicity: 50000  # save intermediate payload results every X processed files
  speechbrain_embedding:
    performance_measurement: true
    save_payload: true
    save_payload_periodicity: 50000  # save intermediate payload results every X processed files
    model: spkrec-ecapa-voxceleb  # e.g. spkrec-ecapa-voxceleb, spkrec-xvect-voxceleb, ...

segment_classifier:
  common_voices_gender:
    pretrained_models_dir: 'pretrained_models/common_voice'
    classification_column_name: 'common_voices_gender_classification'
    verbal_labels: true
    save_payload: true

  common_voices_age:
    pretrained_models_dir: 'pretrained_models/common_voice'
    classification_column_name: 'common_voices_age_classification'
    verbal_labels: true
    save_payload: true

  speech_brain_iemocap_emotion:
    pretrained_models_dir: 'pretrained_models/speech_brain_iemocap_emotion'
    classification_column_name: 'speech_brain_iemocap_emotion'
    verbal_labels: true
    save_payload: true

  wav2vec2stt:
    pretrained_models_dir: 'pretrained_models/wav2vec2'
    classification_column_name: 'wav2vec2_trainscript'
    performance_measurement: true
    save_payload: true
